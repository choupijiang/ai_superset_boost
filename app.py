from flask import Flask, render_template, request, jsonify, send_from_directory
import os
import asyncio
import json
import logging
from datetime import datetime
from superset_automation import SupersetAutomation
from ai_analyzer import AIAnalyzer

app = Flask(__name__)
app.secret_key = os.environ.get('SECRET_KEY', 'dev-secret-key')

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@app.route('/')
def index():
    logger.info("ğŸ“± ç”¨æˆ·è®¿é—®é¦–é¡µ")
    return render_template('index.html')

def run_async_analysis(question):
    """Run async analysis in a separate thread"""
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    try:
        return loop.run_until_complete(analyze_question_async(question))
    finally:
        loop.close()

async def analyze_question_async(question):
    """Async analysis function with detailed dashboard exploration"""
    async with SupersetAutomation() as superset_automation:
        ai_analyzer = AIAnalyzer()
        
        try:
            # Step 1: Capture detailed dashboard information with charts
            print("ğŸš€ Starting detailed dashboard analysis...")
            dashboards_data = await superset_automation.capture_all_dashboards_with_details()
            
            if not dashboards_data:
                # No dashboard data available
                print("âš ï¸  æ— æ³•è·å–çœ‹æ¿æ•°æ®")
                return {
                    'question': question,
                    'answer': 'æŠ±æ­‰ï¼Œç›®å‰æ— æ³•è¿æ¥åˆ°Supersetæˆ–è·å–çœ‹æ¿æ•°æ®ã€‚\n\nå¯èƒ½çš„åŸå› ï¼š\n1. SupersetæœåŠ¡æœªè¿è¡Œï¼ˆè¯·æ£€æŸ¥ http://localhost:8088ï¼‰\n2. ç½‘ç»œè¿æ¥é—®é¢˜\n3. ç™»å½•å‡­æ®é”™è¯¯\n4. Superseté…ç½®é—®é¢˜\n\nå»ºè®®è§£å†³æ–¹æ¡ˆï¼š\n- ç¡®è®¤SupersetæœåŠ¡å·²å¯åŠ¨\n- æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®ï¼ˆ.envæ–‡ä»¶ï¼‰\n- éªŒè¯SUPERSET_URLã€SUPERSET_USERNAMEã€SUPERSET_PASSWORDæ˜¯å¦æ­£ç¡®\n- ç¨åé‡è¯•',
                    'timestamp': datetime.now().isoformat(),
                    'analysis_type': 'no_data',
                    'dashboards_analyzed': 0,
                    'total_charts': 0,
                    'dashboards_data': [],
                    'chart_summary': [],
                    'screenshots': []
                }
            
            # Step 2: Prepare comprehensive analysis data
            print("ğŸ“Š Preparing comprehensive analysis data...")
            
            # Extract all screenshots for AI analysis
            all_screenshots = []
            chart_data_summary = []
            
            for dashboard in dashboards_data:
                # Add dashboard screenshot
                if dashboard.get('dashboard_screenshot'):
                    all_screenshots.append({
                        'title': f"{dashboard['dashboard_title']} - å®Œæ•´çœ‹æ¿",
                        'path': dashboard['dashboard_screenshot'],
                        'type': 'dashboard'
                    })
                
                # Add chart screenshots and data
                for chart in dashboard.get('charts', []):
                    if chart.get('chart_screenshot'):
                        all_screenshots.append({
                            'title': f"{chart['chart_title']} - å›¾è¡¨",
                            'path': chart['chart_screenshot'],
                            'type': 'chart'
                        })
                    
                    # Add chart data summary
                    chart_data_summary.append({
                        'dashboard': dashboard['dashboard_title'],
                        'chart': chart['chart_title'],
                        'data_type': chart.get('chart_data', {}).get('type', 'unknown'),
                        'key_metrics': _extract_key_metrics(chart.get('chart_data', {}))
                    })
            
            # Step 3: Analyze with AI
            print("ğŸ¤– Starting AI analysis...")
            dashboard_titles = [d['dashboard_title'] for d in dashboards_data]
            
            try:
                if all_screenshots and any(os.path.exists(s['path']) for s in all_screenshots):
                    # Use vision model if screenshots are available
                    answer = ai_analyzer.analyze_with_screenshots(question, all_screenshots)
                else:
                    # Fallback to text-only analysis with enhanced data
                    enhanced_context = _create_enhanced_context(question, dashboards_data, chart_data_summary)
                    answer = ai_analyzer.analyze_text_only(enhanced_context, dashboard_titles)
            except Exception as ai_error:
                print(f"AI analysis failed: {ai_error}")
                # Provide helpful error message instead of template fallback
                return {
                    'question': question,
                    'answer': f'æŠ±æ­‰ï¼ŒAIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚æˆ‘ä»¬å·²ç»æˆåŠŸè·å–äº†çœ‹æ¿æ•°æ®ï¼Œä½†æ— æ³•è¿›è¡Œåˆ†æã€‚\n\næŠ€æœ¯è¯¦æƒ…ï¼š{str(ai_error)}\n\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š\n- æ£€æŸ¥AI APIå¯†é’¥é…ç½®ï¼ˆOPENAI_API_KEYï¼‰\n- ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸\n- éªŒè¯APIæœåŠ¡çŠ¶æ€\n- ç¨åé‡è¯•\n\nå·²è·å–çš„æ•°æ®ï¼š\n- åˆ†æäº† {len(dashboards_data)} ä¸ªçœ‹æ¿\n- åŒ…å« {sum(len(d.get("charts", [])) for d in dashboards_data)} ä¸ªå›¾è¡¨',
                    'timestamp': datetime.now().isoformat(),
                    'analysis_type': 'ai_error',
                    'dashboards_analyzed': len(dashboards_data),
                    'total_charts': sum(len(d.get('charts', [])) for d in dashboards_data),
                    'dashboards_data': dashboards_data,
                    'chart_summary': chart_data_summary,
                    'screenshots': all_screenshots
                }
            
            return {
                'question': question,
                'answer': answer,
                'timestamp': datetime.now().isoformat(),
                'analysis_type': 'detailed',
                'dashboards_analyzed': len(dashboards_data),
                'total_charts': sum(len(d.get('charts', [])) for d in dashboards_data),
                'dashboards_data': dashboards_data,
                'chart_summary': chart_data_summary,
                'screenshots': all_screenshots
            }
            
        except Exception as e:
            print(f"âŒ Analysis failed: {e}")
            return {
                'question': question,
                'answer': f'æŠ±æ­‰ï¼Œåˆ†æè¿‡ç¨‹ä¸­é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ã€‚\n\né”™è¯¯è¯¦æƒ…ï¼š{str(e)}\n\nå»ºè®®è§£å†³æ–¹æ¡ˆï¼š\n- æ£€æŸ¥SupersetæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ\n- ç¡®è®¤ç½‘ç»œè¿æ¥ç¨³å®š\n- éªŒè¯æµè§ˆå™¨è‡ªåŠ¨åŒ–ç»„ä»¶æ˜¯å¦æ­£å¸¸\n- ç¨åé‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒ\n\næŠ€æœ¯æ”¯æŒä¿¡æ¯ï¼š\n- è¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ï¼šapp.log, superset_automation.log\n- ç¡®è®¤æ‰€æœ‰ä¾èµ–é¡¹å·²æ­£ç¡®å®‰è£…',
                'timestamp': datetime.now().isoformat(),
                'analysis_type': 'error',
                'dashboards_analyzed': 0,
                'total_charts': 0,
                'dashboards_data': [],
                'chart_summary': [],
                'screenshots': []
            }

def _extract_key_metrics(chart_data):
    """Extract key metrics from chart data"""
    try:
        metrics = []
        data = chart_data.get('data', {})
        
        if 'total_sales' in data:
            metrics.append(f"æ€»é”€å”®é¢: {data['total_sales']:,}")
        if 'growth_rate' in data:
            metrics.append(f"å¢é•¿ç‡: {data['growth_rate']}%")
        if 'total_users' in data:
            metrics.append(f"æ€»ç”¨æˆ·æ•°: {data['total_users']:,}")
        if 'active_users' in data:
            metrics.append(f"æ´»è·ƒç”¨æˆ·: {data['active_users']:,}")
        if 'retention_rate' in data:
            metrics.append(f"ç•™å­˜ç‡: {data['retention_rate']}%")
        if 'value' in data:
            metrics.append(f"æ•°å€¼: {data['value']:,}")
        
        return metrics if metrics else ["æ•°æ®ä¸å¯ç”¨"]
    except:
        return ["æ•°æ®æå–å¤±è´¥"]

def _create_enhanced_context(question, dashboards_data, chart_summary):
    """Create enhanced context for AI analysis"""
    context = f"ä¸šåŠ¡é—®é¢˜: {question}\n\n"
    context += "å¯ç”¨çš„çœ‹æ¿å’Œå›¾è¡¨æ•°æ®:\n\n"
    
    for dashboard in dashboards_data:
        context += f"ğŸ“Š {dashboard['dashboard_title']}:\n"
        for chart in dashboard.get('charts', []):
            context += f"  ğŸ“ˆ {chart['chart_title']}\n"
            
            # Add key metrics
            metrics = _extract_key_metrics(chart.get('chart_data', {}))
            for metric in metrics:
                context += f"    â€¢ {metric}\n"
        context += "\n"
    
    context += "è¯·åŸºäºä»¥ä¸Šè¯¦ç»†çš„çœ‹æ¿å’Œå›¾è¡¨æ•°æ®åˆ†æä¸šåŠ¡é—®é¢˜ï¼Œæä¾›å…·ä½“çš„æ´å¯Ÿå’Œå»ºè®®ã€‚"
    
    return context

@app.route('/analyze', methods=['POST'])
def analyze():
    logger.info("ğŸ” æ”¶åˆ°åˆ†æè¯·æ±‚")
    try:
        data = request.get_json()
        question = data.get('question', '')
        
        logger.info(f"ğŸ“ ç”¨æˆ·é—®é¢˜: {question}")
        
        if not question:
            logger.warning("âš ï¸ ç”¨æˆ·é—®é¢˜ä¸ºç©º")
            return jsonify({'error': 'Question is required'}), 400
        
        logger.info("ğŸš€ å¼€å§‹å¼‚æ­¥åˆ†æ")
        # Run analysis in a separate thread to avoid blocking
        import concurrent.futures
        
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future = executor.submit(run_async_analysis, question)
            result = future.result(timeout=120)  # 2 minute timeout
        
        logger.info(f"âœ… åˆ†æå®Œæˆï¼Œåˆ†æäº† {result.get('dashboards_analyzed', 0)} ä¸ªçœ‹æ¿")
        return jsonify(result)
    
    except concurrent.futures.TimeoutError:
        logger.error("â° åˆ†æè¶…æ—¶")
        return jsonify({
            'error': 'åˆ†æè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•æˆ–ç®€åŒ–é—®é¢˜ã€‚\n\nå¯èƒ½çš„åŸå› ï¼š\n- ç½‘ç»œè¿æ¥ç¼“æ…¢\n- Supersetå“åº”æ—¶é—´è¿‡é•¿\n- çœ‹æ¿æ•°æ®é‡è¿‡å¤§\n- AIæœåŠ¡å“åº”å»¶è¿Ÿ\n\nå»ºè®®ï¼š\n- ç®€åŒ–åˆ†æé—®é¢˜\n- ç¨åé‡è¯•\n- æ£€æŸ¥ç½‘ç»œè¿æ¥çŠ¶æ€'
        }), 504
    except Exception as e:
        logger.error(f"âŒ åˆ†æè¯·æ±‚å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/screenshots/<filename>')
def serve_screenshot(filename):
    """Serve screenshot files"""
    logger.info(f"ğŸ–¼ï¸ ç”¨æˆ·è¯·æ±‚æˆªå›¾: {filename}")
    try:
        # Check if file exists in screenshots directory
        screenshots_dir = os.path.join(os.path.dirname(__file__), 'screenshots')
        file_path = os.path.join(screenshots_dir, filename)
        
        if not os.path.exists(file_path):
            logger.error(f"âŒ æˆªå›¾æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return jsonify({'error': 'Screenshot not found', 'path': file_path}), 404
        
        logger.info(f"âœ… æ‰¾åˆ°æˆªå›¾æ–‡ä»¶: {file_path}")
        return send_from_directory(screenshots_dir, filename)
    except Exception as e:
        logger.error(f"âŒ æˆªå›¾æœåŠ¡å¤±è´¥ {filename}: {e}")
        return jsonify({'error': f'Screenshot service error: {str(e)}'}), 404

@app.route('/health')
def health_check():
    """Health check endpoint"""
    logger.info("ğŸ’“ å¥åº·æ£€æŸ¥è¯·æ±‚")
    return jsonify({'status': 'healthy', 'timestamp': datetime.now().isoformat()})

if __name__ == '__main__':
    logger.info("ğŸš€ å¯åŠ¨ Flask åº”ç”¨æœåŠ¡å™¨")
    app.run(debug=True, host='0.0.0.0', port=5002)